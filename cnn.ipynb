{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 using Simple Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from keras import Model, Input\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on let's normalize the imgae data so that it is between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the labels are intergers let's convert them into array for simpler processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_shape = (32,32,3), classes = 10) :\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #Convolution Block 1\n",
    "    X = Conv2D(filters = 16, kernel_size=(3,3), activation = \"relu\", padding = \"Same\")(X_input)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 2\n",
    "    X = Conv2D(filters = 32, kernel_size=(3,3), activation = \"relu\", padding = \"Same\")(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 3\n",
    "    X = Conv2D(filters = 64, kernel_size=(3,3), activation = \"relu\", padding = \"Same\")(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(100, activation = 'relu')(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X_output = Dense(10, activation = 'softmax')(X)\n",
    "    \n",
    "    model = Model(X_input, X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name the model and see it's structure and other important architectural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 32, 32, 16)        448       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 16, 16, 16)        64        \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 16, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 8, 8, 32)          128       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 64)          18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 4, 4, 64)          256       \n_________________________________________________________________\nflatten (Flatten)            (None, 1024)              0         \n_________________________________________________________________\ndense (Dense)                (None, 100)               102500    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 100)               400       \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1010      \n=================================================================\nTotal params: 127,942\nTrainable params: 127,518\nNon-trainable params: 424\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn(input_shape = (32,32,3), classes = 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below defines the important hyperparameters for training of model.<br>\n",
    "We're using learning rate decay for smoother and accurate training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=5000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "391/391 [==============================] - 42s 107ms/step - loss: 1.2835 - accuracy: 0.5425\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 46s 116ms/step - loss: 0.8995 - accuracy: 0.6806\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 41s 106ms/step - loss: 0.7579 - accuracy: 0.7323\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 41s 105ms/step - loss: 0.6594 - accuracy: 0.7700\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 41s 106ms/step - loss: 0.5843 - accuracy: 0.7925\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 43s 109ms/step - loss: 0.5221 - accuracy: 0.8149\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 46s 119ms/step - loss: 0.4540 - accuracy: 0.8395\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 48s 122ms/step - loss: 0.3985 - accuracy: 0.8574\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 0.3530 - accuracy: 0.8753\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 46s 118ms/step - loss: 0.3098 - accuracy: 0.8895\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 46s 118ms/step - loss: 0.2779 - accuracy: 0.9013\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 0.2451 - accuracy: 0.9124\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 44s 111ms/step - loss: 0.2252 - accuracy: 0.9196\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 43s 110ms/step - loss: 0.1997 - accuracy: 0.9276\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 42s 109ms/step - loss: 0.1755 - accuracy: 0.9372\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 42s 108ms/step - loss: 0.1589 - accuracy: 0.9429\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 43s 110ms/step - loss: 0.1519 - accuracy: 0.9452\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 46s 116ms/step - loss: 0.1395 - accuracy: 0.9504\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 0.1305 - accuracy: 0.9538\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 0.1111 - accuracy: 0.9599\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x288c456ed30>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss: 1.5554429292678833\nTest accuracy: 0.7289999723434448\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite5dc68241b3e4559aae846c0e3ff9206",
   "display_name": "Python 3.8.2 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}