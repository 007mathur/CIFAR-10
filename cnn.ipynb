{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 using Simple Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from keras import Model, Input\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on let's normalize the imgae data so that it is between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((50000, 32, 32, 3), (50000, 1))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the labels are intergers let's convert them into array for simpler processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_shape = (32,32,3), classes = 10) :\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #Convolution Block 1\n",
    "    X = Conv2D(filters = 6, kernel_size=(3,3), activation = \"relu\", padding = \"Same\")(X_input)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 2\n",
    "    X = Conv2D(filters = 16, kernel_size=(3,3), activation = \"relu\", padding = \"Same\")(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 3\n",
    "    X = Conv2D(filters = 32, kernel_size=(3,3), activation = \"relu\", padding = \"Same\")(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(32, activation = 'relu')(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X_output = Dense(10, activation = 'softmax')(X)\n",
    "    \n",
    "    model = Model(X_input, X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name the model and see it's structure and other important architectural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 32, 32, 3)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 6)         168       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 6)         0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 16, 16, 6)         24        \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 16, 16, 16)        880       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 8, 8, 16)          64        \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 8, 8, 32)          4640      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 4, 4, 32)          128       \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                16416     \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 32)                128       \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 22,778\nTrainable params: 22,606\nNon-trainable params: 172\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = cnn(input_shape = (32,32,3), classes = 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below defines the important hyperparameters for training of model.<br>\n",
    "We're using learning rate decay for smoother and accurate training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 20\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n50000/50000 [==============================] - 17s 330us/step - loss: 1.3599 - accuracy: 0.5119\nEpoch 2/20\n50000/50000 [==============================] - 17s 349us/step - loss: 1.0516 - accuracy: 0.6272\nEpoch 3/20\n50000/50000 [==============================] - 17s 347us/step - loss: 0.9397 - accuracy: 0.6697\nEpoch 4/20\n50000/50000 [==============================] - 19s 373us/step - loss: 0.8787 - accuracy: 0.6902\nEpoch 5/20\n50000/50000 [==============================] - 19s 390us/step - loss: 0.8246 - accuracy: 0.7109\nEpoch 6/20\n50000/50000 [==============================] - 17s 341us/step - loss: 0.7824 - accuracy: 0.7231\nEpoch 7/20\n50000/50000 [==============================] - 17s 336us/step - loss: 0.7521 - accuracy: 0.7338\nEpoch 8/20\n50000/50000 [==============================] - 17s 335us/step - loss: 0.7298 - accuracy: 0.7438\nEpoch 9/20\n50000/50000 [==============================] - 17s 334us/step - loss: 0.7032 - accuracy: 0.7523\nEpoch 10/20\n50000/50000 [==============================] - 17s 334us/step - loss: 0.6897 - accuracy: 0.7556\nEpoch 11/20\n50000/50000 [==============================] - 17s 337us/step - loss: 0.6701 - accuracy: 0.7640\nEpoch 12/20\n50000/50000 [==============================] - 17s 338us/step - loss: 0.6541 - accuracy: 0.7677\nEpoch 13/20\n50000/50000 [==============================] - 17s 340us/step - loss: 0.6368 - accuracy: 0.7736\nEpoch 14/20\n50000/50000 [==============================] - 17s 340us/step - loss: 0.6223 - accuracy: 0.7787\nEpoch 15/20\n50000/50000 [==============================] - 17s 348us/step - loss: 0.6126 - accuracy: 0.7829\nEpoch 16/20\n50000/50000 [==============================] - 17s 340us/step - loss: 0.5993 - accuracy: 0.7886\nEpoch 17/20\n50000/50000 [==============================] - 17s 346us/step - loss: 0.5893 - accuracy: 0.7906\nEpoch 18/20\n50000/50000 [==============================] - 17s 343us/step - loss: 0.5855 - accuracy: 0.7902\nEpoch 19/20\n50000/50000 [==============================] - 17s 343us/step - loss: 0.5638 - accuracy: 0.7991\nEpoch 20/20\n50000/50000 [==============================] - 17s 343us/step - loss: 0.5563 - accuracy: 0.8017\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x20b36d5d160>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test loss: 1.0777778217315674\nTest accuracy: 0.6739000082015991\n"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite5dc68241b3e4559aae846c0e3ff9206",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}