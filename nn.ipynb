{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras import Model , Input\n",
    "from keras.layers import Flatten , Dense , BatchNormalization \n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Processing Data \n",
    "The data is downloaded and imported from keras itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on let's normalize the imgae data so that it is between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((50000, 32, 32, 3), (50000, 1))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the labels are intergers let's convert them into array for simpler processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(input_shape = (32,32,3), classes = 10) :\n",
    "    X_input = Input(input_shape)\n",
    "        \n",
    "    X = Flatten()(X_input)\n",
    "    X = Dense(784, activation = 'relu')(X)\n",
    "    X = Dense(84, activation = 'relu')(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X = Dense(20, activation = 'relu')(X)\n",
    "    X_output = Dense(10, activation = 'softmax')(X)\n",
    "    \n",
    "    model = Model(X_input, X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name the model and see it's structure and other important architectural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 32, 32, 3)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3072)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 784)               2409232   \n_________________________________________________________________\ndense_2 (Dense)              (None, 84)                65940     \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 84)                336       \n_________________________________________________________________\ndense_3 (Dense)              (None, 20)                1700      \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                210       \n=================================================================\nTotal params: 2,477,418\nTrainable params: 2,477,250\nNon-trainable params: 168\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = neural_net(input_shape = (32,32,3), classes = 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below defines the important hyperparameters for training of model.<br>\n",
    "We're using learning rate decay for smoother and accurate training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 15\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n50000/50000 [==============================] - 11s 224us/step - loss: 1.8876 - accuracy: 0.3055\nEpoch 2/15\n50000/50000 [==============================] - 11s 214us/step - loss: 1.6949 - accuracy: 0.3889\nEpoch 3/15\n50000/50000 [==============================] - 11s 211us/step - loss: 1.6165 - accuracy: 0.4209\nEpoch 4/15\n50000/50000 [==============================] - 11s 212us/step - loss: 1.5684 - accuracy: 0.4379\nEpoch 5/15\n50000/50000 [==============================] - 11s 211us/step - loss: 1.5198 - accuracy: 0.4570\nEpoch 6/15\n50000/50000 [==============================] - 10s 207us/step - loss: 1.4830 - accuracy: 0.4683\nEpoch 7/15\n50000/50000 [==============================] - 10s 208us/step - loss: 1.4542 - accuracy: 0.4795\nEpoch 8/15\n50000/50000 [==============================] - 10s 207us/step - loss: 1.4260 - accuracy: 0.4900\nEpoch 9/15\n50000/50000 [==============================] - 11s 214us/step - loss: 1.3970 - accuracy: 0.4993\nEpoch 10/15\n50000/50000 [==============================] - 11s 217us/step - loss: 1.3796 - accuracy: 0.5065\nEpoch 11/15\n50000/50000 [==============================] - 11s 218us/step - loss: 1.3525 - accuracy: 0.5145\nEpoch 12/15\n50000/50000 [==============================] - 11s 210us/step - loss: 1.3351 - accuracy: 0.5235\nEpoch 13/15\n50000/50000 [==============================] - 11s 212us/step - loss: 1.3232 - accuracy: 0.5271\nEpoch 14/15\n50000/50000 [==============================] - 10s 191us/step - loss: 1.3045 - accuracy: 0.5342\nEpoch 15/15\n50000/50000 [==============================] - 5s 107us/step - loss: 1.2847 - accuracy: 0.5389\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x26571879f70>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer , metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test loss: 1.5811723743438721\nTest accuracy: 0.4366999864578247\n"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite5dc68241b3e4559aae846c0e3ff9206",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}