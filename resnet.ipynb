{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 using Residual Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from keras import Model, Input\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Add, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on let's normalize the imgae data so that it is between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the labels are intergers let's convert them into array for simpler processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for Convolution blocks and Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(X, filters, f = 3):\n",
    "    X_shortcut = X\n",
    "    F1, F2 = filters \n",
    "    \n",
    "    # For the convolutional part\n",
    "    X = Conv2D(filters = F1  , kernel_size=(f,f), activation = \"relu\", padding = \"Same\")(X)\n",
    "    X = Conv2D(filters = F2, kernel_size=(f,f), activation = \"relu\", padding = \"Same\")(X)\n",
    "\n",
    "    # For the shortcut path\n",
    "    X_shortcut = Conv2D(filters = F2, kernel_size=(1,1), activation = \"relu\", padding = \"Same\")(X_shortcut)\n",
    "\n",
    "    #\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net(input_shape = (32,32,3), classes = 10) :\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Conv2D(8, kernel_size = (3,3), activation = 'relu', padding = \"Same\")(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 1\n",
    "    X = convolution_block(X, filters = [8,16] , f = 5)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides =2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 2\n",
    "    X = convolution_block(X, filters = [16,32] , f = 5)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides =2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Convolution Block 3\n",
    "    X = convolution_block(X, filters = [32,63] , f = 3)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides =2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    #Convolution Block 4\n",
    "    X = Conv2D(128, kernel_size = (3,3), activation = 'relu', padding = \"Same\")(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(200, activation = 'relu')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X_output = Dense(10, activation = 'softmax')(X)\n",
    "    \n",
    "    model = Model(X_input, X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name the model and see it's structure and other important architectural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 32, 32, 8)    224         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 32, 32, 8)    32          conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 8)    1608        batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 32, 32, 16)   144         batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 16)   3216        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 32, 32, 16)   0           conv2d_3[0][0]                   \n                                                                 conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 32, 32, 16)   0           add[0][0]                        \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 16, 16, 16)   0           activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 16, 16, 16)   64          max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 16, 16, 16)   6416        batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 16, 16, 32)   544         batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 16, 16, 32)   12832       conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 16, 16, 32)   0           conv2d_6[0][0]                   \n                                                                 conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 16, 16, 32)   0           add_1[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 8, 8, 32)     128         max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 8, 8, 32)     9248        batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 8, 8, 63)     2079        batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 8, 8, 63)     18207       conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 8, 8, 63)     0           conv2d_9[0][0]                   \n                                                                 conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 8, 8, 63)     0           add_2[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 63)     0           activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 4, 4, 63)     252         max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 4, 4, 128)    72704       batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 2048)         0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 200)          409800      flatten[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 200)          800         dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           2010        batch_normalization_5[0][0]      \n==================================================================================================\nTotal params: 540,820\nTrainable params: 539,926\nNon-trainable params: 894\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = res_net(input_shape = (32,32,3), classes = 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model\n",
    "This code below defines the important hyperparameters for training of model.<br>\n",
    "We're using learning rate decay for smoother and accurate training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=5000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 224s 287ms/step - loss: 1.4015 - accuracy: 0.5015\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 218s 279ms/step - loss: 0.9226 - accuracy: 0.6733\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 234s 299ms/step - loss: 0.7424 - accuracy: 0.7390\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 256s 328ms/step - loss: 0.6380 - accuracy: 0.7781\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 241s 308ms/step - loss: 0.5571 - accuracy: 0.8060\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 243s 311ms/step - loss: 0.4837 - accuracy: 0.8297\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 242s 310ms/step - loss: 0.4136 - accuracy: 0.8551\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 275s 352ms/step - loss: 0.3545 - accuracy: 0.8753\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 305s 390ms/step - loss: 0.2907 - accuracy: 0.8967\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 320s 410ms/step - loss: 0.2463 - accuracy: 0.9117\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 328s 419ms/step - loss: 0.2044 - accuracy: 0.9262\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 283s 361ms/step - loss: 0.1765 - accuracy: 0.9374\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 330s 422ms/step - loss: 0.1582 - accuracy: 0.9434\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 347s 444ms/step - loss: 0.1382 - accuracy: 0.9516\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 384s 491ms/step - loss: 0.1246 - accuracy: 0.9567\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 379s 484ms/step - loss: 0.1135 - accuracy: 0.9608\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 200s 256ms/step - loss: 0.0952 - accuracy: 0.9673\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.0919 - accuracy: 0.9679\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 178s 227ms/step - loss: 0.0868 - accuracy: 0.9701\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 179s 229ms/step - loss: 0.0854 - accuracy: 0.9699\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17fddda9cd0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer , metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss: 1.2895078659057617\nTest accuracy: 0.7775999903678894\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite5dc68241b3e4559aae846c0e3ff9206",
   "display_name": "Python 3.8.2 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}