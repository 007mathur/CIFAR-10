{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 using Residual Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from keras import Model, Input\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Add, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on let's normalize the imgae data so that it is between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((50000, 32, 32, 3), (50000, 1))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the labels are intergers let's convert them into array for simpler processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for Convolution blocks and Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(X, filters, f = 3):\n",
    "    X_shortcut = X\n",
    "    F1, F2 = filters \n",
    "    \n",
    "    # For the convolutional part\n",
    "    X = Conv2D(filters = F1  , kernel_size=(f,f), activation = \"relu\", padding = \"Same\")(X)\n",
    "    X = Conv2D(filters = F2, kernel_size=(f,f), activation = \"relu\", padding = \"Same\")(X)\n",
    "\n",
    "    # For the shortcut path\n",
    "    X_shortcut = Conv2D(filters = F2, kernel_size=(1,1), activation = \"relu\", padding = \"Same\")(X_shortcut)\n",
    "\n",
    "    #\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net(input_shape = (32,32,3), classes = 10) :\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #Convolution Block 1\n",
    "    X = convolution_block(X_input, filters = [3,6] , f = 5)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides =2)(X)\n",
    "    \n",
    "    #Convolution Block 2\n",
    "    X = convolution_block(X, filters = [6,16] , f = 5)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides =2)(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    \n",
    "    #Convolution Block 3\n",
    "    X = convolution_block(X, filters = [16,32] , f = 3)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides =2)(X)\n",
    "\n",
    "    #Convolution Block 4\n",
    "    X = Conv2D(64, kernel_size = (3,3), activation = 'relu', padding = \"Valid\")(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(32, activation = 'relu')(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X_output = Dense(10, activation = 'softmax')(X)\n",
    "    \n",
    "    model = Model(X_input, X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name the model and see it's structure and other important architectural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 3)    228         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 32, 32, 6)    24          input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 6)    456         conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n                                                                 conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 32, 6)    0           add_1[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 6)    0           activation_1[0][0]               \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 16, 16, 6)    906         max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 16, 16, 16)   112         max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 16, 16, 16)   2416        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 16, 16, 16)   0           conv2d_6[0][0]                   \n                                                                 conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 16, 16, 16)   0           add_2[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 16)     0           activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 8, 8, 16)     64          max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 8, 8, 16)     2320        batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 8, 8, 32)     544         batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 8, 8, 32)     4640        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 8, 8, 32)     0           conv2d_9[0][0]                   \n                                                                 conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 8, 8, 32)     0           add_3[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 32)     0           activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 2, 2, 64)     18496       max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 2, 2, 64)     256         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 256)          0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 32)           8224        flatten_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 32)           128         dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 10)           330         batch_normalization_3[0][0]      \n==================================================================================================\nTotal params: 39,144\nTrainable params: 38,920\nNon-trainable params: 224\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model = res_net(input_shape = (32,32,3), classes = 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model\n",
    "This code below defines the important hyperparameters for training of model.<br>\n",
    "We're using learning rate decay for smoother and accurate training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 20\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n50000/50000 [==============================] - 46s 923us/step - loss: 1.6222 - accuracy: 0.4088\nEpoch 2/20\n50000/50000 [==============================] - 44s 886us/step - loss: 1.2936 - accuracy: 0.5326\nEpoch 3/20\n50000/50000 [==============================] - 44s 886us/step - loss: 1.1634 - accuracy: 0.5830\nEpoch 4/20\n50000/50000 [==============================] - 45s 895us/step - loss: 1.0596 - accuracy: 0.6245\nEpoch 5/20\n50000/50000 [==============================] - 46s 923us/step - loss: 0.9847 - accuracy: 0.6523\nEpoch 6/20\n50000/50000 [==============================] - 47s 934us/step - loss: 0.9288 - accuracy: 0.6714\nEpoch 7/20\n50000/50000 [==============================] - 44s 876us/step - loss: 0.8768 - accuracy: 0.6907\nEpoch 8/20\n50000/50000 [==============================] - 44s 876us/step - loss: 0.8339 - accuracy: 0.7066\nEpoch 9/20\n50000/50000 [==============================] - 43s 868us/step - loss: 0.8020 - accuracy: 0.7176\nEpoch 10/20\n50000/50000 [==============================] - 44s 875us/step - loss: 0.7735 - accuracy: 0.7267\nEpoch 11/20\n50000/50000 [==============================] - 43s 869us/step - loss: 0.7451 - accuracy: 0.7378\nEpoch 12/20\n50000/50000 [==============================] - 44s 876us/step - loss: 0.7192 - accuracy: 0.7472\nEpoch 13/20\n50000/50000 [==============================] - 44s 880us/step - loss: 0.6964 - accuracy: 0.7547\nEpoch 14/20\n50000/50000 [==============================] - 44s 875us/step - loss: 0.6821 - accuracy: 0.7598\nEpoch 15/20\n50000/50000 [==============================] - 44s 883us/step - loss: 0.6634 - accuracy: 0.7664\nEpoch 16/20\n50000/50000 [==============================] - 46s 920us/step - loss: 0.6468 - accuracy: 0.7731\nEpoch 17/20\n50000/50000 [==============================] - 46s 922us/step - loss: 0.6297 - accuracy: 0.7778\nEpoch 18/20\n50000/50000 [==============================] - 48s 957us/step - loss: 0.6177 - accuracy: 0.7819\nEpoch 19/20\n50000/50000 [==============================] - 70s 1ms/step - loss: 0.6023 - accuracy: 0.7886\nEpoch 20/20\n50000/50000 [==============================] - 71s 1ms/step - loss: 0.5936 - accuracy: 0.7885\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x1c7129d7ac0>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer , metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test loss: 0.960006473827362\nTest accuracy: 0.6926000118255615\n"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite5dc68241b3e4559aae846c0e3ff9206",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}